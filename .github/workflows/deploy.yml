# GitHub Actions Deployment Workflow for XYZ Hotel Lagos Landing Page
# Deploys containerized application to Kubernetes across multiple environments
# Implements blue-green deployment strategy for production with rollback capability

name: Deploy to Kubernetes

# Trigger deployment on push to main branch or manual workflow dispatch
on:
  push:
    branches:
      - main
  workflow_dispatch:
    inputs:
      environment:
        description: 'Target environment for deployment'
        required: true
        type: choice
        options:
          - development
          - staging
          - production
      skip_health_checks:
        description: 'Skip health check validation'
        required: false
        type: boolean
        default: false

# Environment variables used across all jobs
env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  # ==========================================================================
  # JOB 1: Deploy to Development Environment
  # Automatic deployment triggered on push to main branch
  # ==========================================================================
  deploy-dev:
    name: Deploy to Development
    runs-on: ubuntu-latest
    
    # GitHub environment configuration for development
    environment:
      name: development
      url: ${{ steps.deployment.outputs.url }}
    
    # Only run if push to main or manual dispatch with development selected
    if: github.event_name == 'push' || (github.event_name == 'workflow_dispatch' && inputs.environment == 'development')
    
    steps:
      # Checkout repository code for deployment manifests
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 1
      
      # Install and configure kubectl for Kubernetes operations
      - name: Setup kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: 'v1.28.0'
      
      # Configure kubectl with development cluster credentials
      # Uses GitHub secret containing base64-encoded kubeconfig
      - name: Configure kubeconfig for development
        run: |
          mkdir -p $HOME/.kube
          echo "${{ secrets.KUBECONFIG }}" | base64 -d > $HOME/.kube/config
          chmod 600 $HOME/.kube/config
          
          # Verify cluster connectivity
          kubectl cluster-info
          kubectl get nodes
      
      # Update deployment with new container image
      # Uses rolling update strategy for zero-downtime deployment
      - name: Update deployment image
        run: |
          # Set new image for deployment
          kubectl set image deployment/xyz-hotel-landing-deployment \
            xyz-hotel-landing=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:main-${{ github.sha }} \
            -n default \
            --record
          
          # Add annotation with deployment metadata
          kubectl annotate deployment/xyz-hotel-landing-deployment \
            kubernetes.io/change-cause="Deploy commit ${{ github.sha }} to development" \
            -n default \
            --overwrite
      
      # Apply Kubernetes manifests for any configuration changes
      - name: Apply Kubernetes manifests
        run: |
          # Apply all manifests in order
          kubectl apply -f k8s/configmap.yaml
          kubectl apply -f k8s/deployment.yaml
          kubectl apply -f k8s/service.yaml
          kubectl apply -f k8s/ingress.yaml
          kubectl apply -f k8s/hpa.yaml
      
      # Wait for deployment rollout to complete
      # Timeout after 10 minutes to prevent hanging workflows
      - name: Verify deployment rollout
        run: |
          echo "Waiting for deployment rollout to complete..."
          kubectl rollout status deployment/xyz-hotel-landing-deployment \
            -n default \
            --timeout=10m
          
          # Display deployment status
          kubectl get deployment xyz-hotel-landing-deployment -n default
          kubectl get pods -l app=xyz-hotel-landing -n default
      
      # Get service URL for environment output
      - name: Get service URL
        id: deployment
        run: |
          # Wait for ingress to be ready
          sleep 30
          
          # Get ingress URL
          INGRESS_HOST=$(kubectl get ingress xyz-hotel-landing-ingress -n default -o jsonpath='{.spec.rules[0].host}')
          SERVICE_URL="https://${INGRESS_HOST}"
          
          echo "url=${SERVICE_URL}" >> $GITHUB_OUTPUT
          echo "Deployment URL: ${SERVICE_URL}"
      
      # Run health checks to verify deployment
      - name: Run health checks
        if: ${{ !inputs.skip_health_checks }}
        run: |
          echo "Running health checks..."
          
          # Get service endpoint
          SERVICE_IP=$(kubectl get svc xyz-hotel-landing-service -n default -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
          
          # Wait for service to be ready
          for i in {1..30}; do
            if kubectl run health-check-${{ github.run_id }} \
              --image=curlimages/curl:latest \
              --rm -i --restart=Never \
              --namespace=default \
              -- curl -f http://xyz-hotel-landing-service/health; then
              echo "Health check passed"
              exit 0
            fi
            echo "Attempt $i: Health check failed, retrying in 10 seconds..."
            sleep 10
          done
          
          echo "Health check failed after 30 attempts"
          exit 1
      
      # Rollback deployment on failure
      - name: Rollback on failure
        if: failure()
        run: |
          echo "Deployment failed, initiating rollback..."
          
          # Rollback to previous revision
          kubectl rollout undo deployment/xyz-hotel-landing-deployment -n default
          
          # Wait for rollback to complete
          kubectl rollout status deployment/xyz-hotel-landing-deployment -n default --timeout=5m
          
          echo "Rollback completed successfully"
  
  # ==========================================================================
  # JOB 2: Deploy to Staging Environment
  # Requires successful development deployment
  # ==========================================================================
  deploy-staging:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    needs: deploy-dev
    
    # GitHub environment configuration for staging
    environment:
      name: staging
      url: ${{ steps.deployment.outputs.url }}
    
    # Only run if push to main or manual dispatch with staging selected
    if: github.event_name == 'push' || (github.event_name == 'workflow_dispatch' && inputs.environment == 'staging')
    
    steps:
      # Checkout repository code
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 1
      
      # Setup kubectl
      - name: Setup kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: 'v1.28.0'
      
      # Configure kubectl with staging cluster credentials
      - name: Configure kubeconfig for staging
        run: |
          mkdir -p $HOME/.kube
          echo "${{ secrets.KUBECONFIG }}" | base64 -d > $HOME/.kube/config
          chmod 600 $HOME/.kube/config
          
          # Verify cluster connectivity
          kubectl cluster-info
          kubectl get nodes
      
      # Create staging namespace if it doesn't exist
      - name: Ensure staging namespace exists
        run: |
          kubectl create namespace staging --dry-run=client -o yaml | kubectl apply -f -
      
      # Update deployment with new image in staging namespace
      - name: Update deployment image
        run: |
          kubectl set image deployment/xyz-hotel-landing-deployment \
            xyz-hotel-landing=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:main-${{ github.sha }} \
            -n staging \
            --record
          
          kubectl annotate deployment/xyz-hotel-landing-deployment \
            kubernetes.io/change-cause="Deploy commit ${{ github.sha }} to staging" \
            -n staging \
            --overwrite
      
      # Apply manifests to staging namespace
      - name: Apply Kubernetes manifests
        run: |
          # Apply manifests with staging namespace
          kubectl apply -f k8s/configmap.yaml -n staging
          kubectl apply -f k8s/deployment.yaml -n staging
          kubectl apply -f k8s/service.yaml -n staging
          kubectl apply -f k8s/ingress.yaml -n staging
          kubectl apply -f k8s/hpa.yaml -n staging
      
      # Verify rollout in staging
      - name: Verify deployment rollout
        run: |
          echo "Waiting for staging deployment rollout..."
          kubectl rollout status deployment/xyz-hotel-landing-deployment \
            -n staging \
            --timeout=10m
          
          kubectl get deployment xyz-hotel-landing-deployment -n staging
          kubectl get pods -l app=xyz-hotel-landing -n staging
      
      # Get staging service URL
      - name: Get service URL
        id: deployment
        run: |
          sleep 30
          
          INGRESS_HOST=$(kubectl get ingress xyz-hotel-landing-ingress -n staging -o jsonpath='{.spec.rules[0].host}')
          SERVICE_URL="https://${INGRESS_HOST}"
          
          echo "url=${SERVICE_URL}" >> $GITHUB_OUTPUT
          echo "Staging URL: ${SERVICE_URL}"
      
      # Run health checks for staging
      - name: Run health checks
        if: ${{ !inputs.skip_health_checks }}
        run: |
          echo "Running staging health checks..."
          
          for i in {1..30}; do
            if kubectl run health-check-staging-${{ github.run_id }} \
              --image=curlimages/curl:latest \
              --rm -i --restart=Never \
              --namespace=staging \
              -- curl -f http://xyz-hotel-landing-service.staging/health; then
              echo "Staging health check passed"
              exit 0
            fi
            echo "Attempt $i: Health check failed, retrying..."
            sleep 10
          done
          
          echo "Staging health check failed"
          exit 1
      
      # Rollback staging deployment on failure
      - name: Rollback on failure
        if: failure()
        run: |
          echo "Staging deployment failed, rolling back..."
          kubectl rollout undo deployment/xyz-hotel-landing-deployment -n staging
          kubectl rollout status deployment/xyz-hotel-landing-deployment -n staging --timeout=5m
          echo "Staging rollback completed"
  
  # ==========================================================================
  # JOB 3: Deploy to Production Environment
  # Requires manual approval and successful staging deployment
  # Implements blue-green deployment strategy
  # ==========================================================================
  deploy-prod:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: deploy-staging
    
    # GitHub environment with required reviewers for production
    environment:
      name: production
      url: ${{ steps.deployment.outputs.url }}
    
    # Only run if push to main or manual dispatch with production selected
    if: github.event_name == 'push' || (github.event_name == 'workflow_dispatch' && inputs.environment == 'production')
    
    steps:
      # Checkout repository
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 1
      
      # Setup kubectl
      - name: Setup kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: 'v1.28.0'
      
      # Configure kubectl with production cluster credentials
      - name: Configure kubeconfig for production
        run: |
          mkdir -p $HOME/.kube
          echo "${{ secrets.KUBECONFIG }}" | base64 -d > $HOME/.kube/config
          chmod 600 $HOME/.kube/config
          
          kubectl cluster-info
          kubectl get nodes
      
      # Create production namespace if needed
      - name: Ensure production namespace exists
        run: |
          kubectl create namespace production --dry-run=client -o yaml | kubectl apply -f -
      
      # Implement blue-green deployment strategy
      # Determine current active color and deploy to inactive
      - name: Blue-Green Deployment - Determine Colors
        id: colors
        run: |
          # Get current active color from service selector
          ACTIVE_COLOR=$(kubectl get svc xyz-hotel-landing-service-active -n production -o jsonpath='{.spec.selector.color}' 2>/dev/null || echo "blue")
          
          # Determine new color (opposite of active)
          if [ "$ACTIVE_COLOR" == "blue" ]; then
            NEW_COLOR="green"
          else
            NEW_COLOR="blue"
          fi
          
          echo "active_color=$ACTIVE_COLOR" >> $GITHUB_OUTPUT
          echo "new_color=$NEW_COLOR" >> $GITHUB_OUTPUT
          
          echo "Current active deployment: $ACTIVE_COLOR"
          echo "Deploying to: $NEW_COLOR"
      
      # Deploy to inactive color
      - name: Deploy to inactive environment
        run: |
          NEW_COLOR="${{ steps.colors.outputs.new_color }}"
          
          # Update deployment for new color
          kubectl set image deployment/xyz-hotel-landing-deployment-${NEW_COLOR} \
            xyz-hotel-landing=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:main-${{ github.sha }} \
            -n production \
            --record
          
          kubectl annotate deployment/xyz-hotel-landing-deployment-${NEW_COLOR} \
            kubernetes.io/change-cause="Blue-green deploy commit ${{ github.sha }} to ${NEW_COLOR}" \
            -n production \
            --overwrite
      
      # Apply manifests to new color deployment
      - name: Apply manifests to new deployment
        run: |
          NEW_COLOR="${{ steps.colors.outputs.new_color }}"
          
          # Apply manifests with color label
          kubectl apply -f k8s/configmap.yaml -n production
          kubectl apply -f k8s/deployment.yaml -n production
          kubectl label deployment/xyz-hotel-landing-deployment color=${NEW_COLOR} -n production --overwrite
      
      # Wait for new deployment to be ready
      - name: Verify new deployment rollout
        run: |
          NEW_COLOR="${{ steps.colors.outputs.new_color }}"
          
          echo "Waiting for ${NEW_COLOR} deployment to be ready..."
          kubectl rollout status deployment/xyz-hotel-landing-deployment-${NEW_COLOR} \
            -n production \
            --timeout=15m
          
          kubectl get deployment xyz-hotel-landing-deployment-${NEW_COLOR} -n production
          kubectl get pods -l app=xyz-hotel-landing,color=${NEW_COLOR} -n production
      
      # Run comprehensive health checks on new deployment
      - name: Run health checks on new deployment
        run: |
          NEW_COLOR="${{ steps.colors.outputs.new_color }}"
          
          echo "Running health checks on ${NEW_COLOR} deployment..."
          
          # Get preview service endpoint
          PREVIEW_SERVICE="xyz-hotel-landing-service-${NEW_COLOR}"
          
          # Run health checks
          for i in {1..30}; do
            if kubectl run health-check-prod-${NEW_COLOR}-${{ github.run_id }} \
              --image=curlimages/curl:latest \
              --rm -i --restart=Never \
              --namespace=production \
              -- curl -f http://${PREVIEW_SERVICE}.production/health; then
              echo "Health check passed on ${NEW_COLOR}"
              break
            fi
            
            if [ $i -eq 30 ]; then
              echo "Health check failed on ${NEW_COLOR} after 30 attempts"
              exit 1
            fi
            
            echo "Attempt $i: Health check failed, retrying..."
            sleep 10
          done
      
      # Switch traffic to new deployment
      - name: Switch traffic to new deployment
        id: switch
        run: |
          NEW_COLOR="${{ steps.colors.outputs.new_color }}"
          
          echo "Switching active traffic to ${NEW_COLOR}..."
          
          # Update active service selector to point to new color
          kubectl patch svc xyz-hotel-landing-service-active -n production \
            -p "{\"spec\":{\"selector\":{\"app\":\"xyz-hotel-landing\",\"color\":\"${NEW_COLOR}\"}}}"
          
          echo "Traffic switched to ${NEW_COLOR}"
          echo "switched=true" >> $GITHUB_OUTPUT
      
      # Monitor deployment after traffic switch
      - name: Monitor deployment health
        run: |
          NEW_COLOR="${{ steps.colors.outputs.new_color }}"
          
          echo "Monitoring ${NEW_COLOR} deployment for 120 seconds..."
          sleep 120
          
          # Run continuous health checks
          for i in {1..10}; do
            if ! kubectl run health-check-monitor-${{ github.run_id }}-${i} \
              --image=curlimages/curl:latest \
              --rm -i --restart=Never \
              --namespace=production \
              -- curl -f http://xyz-hotel-landing-service-active.production/health; then
              echo "Health check failed during monitoring"
              exit 1
            fi
            echo "Health check $i passed"
            sleep 10
          done
          
          echo "Deployment monitoring completed successfully"
      
      # Get production URL
      - name: Get production URL
        id: deployment
        run: |
          INGRESS_HOST=$(kubectl get ingress xyz-hotel-landing-ingress -n production -o jsonpath='{.spec.rules[0].host}')
          SERVICE_URL="https://${INGRESS_HOST}"
          
          echo "url=${SERVICE_URL}" >> $GITHUB_OUTPUT
          echo "Production URL: ${SERVICE_URL}"
      
      # Rollback on any failure
      - name: Rollback on failure
        if: failure() && steps.switch.outputs.switched == 'true'
        run: |
          PREVIOUS_COLOR="${{ steps.colors.outputs.active_color }}"
          
          echo "Deployment failed, rolling back to ${PREVIOUS_COLOR}..."
          
          # Switch traffic back to previous color
          kubectl patch svc xyz-hotel-landing-service-active -n production \
            -p "{\"spec\":{\"selector\":{\"app\":\"xyz-hotel-landing\",\"color\":\"${PREVIOUS_COLOR}\"}}}"
          
          echo "Traffic rolled back to ${PREVIOUS_COLOR}"
          
          # Verify rollback
          kubectl get svc xyz-hotel-landing-service-active -n production
          
          echo "Rollback completed successfully"
      
      # Create deployment summary
      - name: Create deployment summary
        if: success()
        run: |
          NEW_COLOR="${{ steps.colors.outputs.new_color }}"
          
          cat >> $GITHUB_STEP_SUMMARY << EOF
          ## Production Deployment Successful
          
          - **Environment**: Production
          - **Strategy**: Blue-Green
          - **Active Color**: ${NEW_COLOR}
          - **Image**: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:main-${{ github.sha }}
          - **Commit**: ${{ github.sha }}
          - **URL**: ${{ steps.deployment.outputs.url }}
          
          ### Deployment Details
          - Previous active: ${{ steps.colors.outputs.active_color }}
          - New active: ${NEW_COLOR}
          - Rollout time: $(date -u +"%Y-%m-%d %H:%M:%S UTC")
          EOF